{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_data(file):\n",
    "    \"\"\"\n",
    "    :param file: input data file \n",
    "    :return: Dict in the form of {data:[[tweets],[sentiments]], x_set:{tweets}, y_set:{sentiments}}\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    dictionary = {}\n",
    "    allKeys = []\n",
    "    allVals = []\n",
    "    \n",
    "    with open(file,'r',encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        #print(len(lines))\n",
    "        index=0\n",
    "        for i in range (len(lines)-2000):\n",
    "            #print(lines[i]) #eg. 'Omg O' is line[0]\n",
    "            if lines[i] == '\\n':\n",
    "                data.append(lines[index:i]) #append everything until it encounters a \\n\n",
    "                index = i+1\n",
    "            lines[i] = lines[i].replace('\\n','')# replace the \\n at the end of each sentiments\n",
    "            lines[i] = lines[i].split(' ') #split the line into their respective parts  \n",
    "            #print(lines[i]) ##format = eg. ['Justin', 'B-neutral']\n",
    "        #convert to keys and values (dict)\n",
    "        for i in range(len(data)):\n",
    "            #print(data[i])\n",
    "            data_values = data[i]\n",
    "            #print(data_values)\n",
    "            for j in range(len(data_values)):\n",
    "                if len(data_values[j]) > 2:\n",
    "                    #print(data_values[j])\n",
    "                    for k in range(1, len(data_values[j]) - 1):\n",
    "                        data_values[j][0] += \" \"\n",
    "                        data_values[j][0] += data_values[j][k]\n",
    "            #key = [data_values[0]]\n",
    "            #val = [data_values[len(data_values) - 1]]\n",
    "                #print(data_values[0])\n",
    "            key = [word[0] for word in data_values] #tweet\n",
    "            val = [word[-1] for word in data_values] #sentiment\n",
    "            #print(key)\n",
    "            #print(val)\n",
    "            data[i] = [key,val]\n",
    "            #dictionary = dict(zip(key,val))\n",
    "            #print(data[i])\n",
    "        #data[i][0] gives the tweets\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data[i][0])):\n",
    "                allVals.append(data[i][1][j]) #appending the sentiments corresponding to the tweets\n",
    "             \n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data[i][0])):\n",
    "                #print(data[i][0][j]) #give each word\n",
    "                allKeys.append(data[i][0][j])\n",
    "        setKeys = set(allKeys)\n",
    "        setVals = set(allVals)   \n",
    "\n",
    "    return dict(data=data,x_set=setKeys,y_set=setVals)\n",
    "\n",
    "\n",
    "#obtain_data('sg_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: (5 pts) Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-positive</th>\n",
       "      <th>O</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://t.co/OgZ1pIXiSD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambridge</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mugen</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@eddiesjb_</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         B-positive         O  B-negative  I-positive  \\\n",
       "https://t.co/OgZ1pIXiSD    0.000000  0.000008         0.0    0.000000   \n",
       "ean                        0.000000  0.000000         0.0    0.000000   \n",
       "Cambridge                  0.000154  0.000000         0.0    0.000704   \n",
       "Mugen                      0.000000  0.000000         0.0    0.000235   \n",
       "@eddiesjb_                 0.000000  0.000004         0.0    0.000000   \n",
       "\n",
       "                         I-neutral  B-neutral  I-negative  \n",
       "https://t.co/OgZ1pIXiSD    0.00000   0.000000         0.0  \n",
       "ean                        0.00006   0.000000         0.0  \n",
       "Cambridge                  0.00012   0.000168         0.0  \n",
       "Mugen                      0.00000   0.000056         0.0  \n",
       "@eddiesjb_                 0.00000   0.000000         0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e(x|y) = Count(y -> x)/Count(y)\n",
    "#Count(y->x) means number of times you see x generated from y\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_emission_count(parsed_data):\n",
    "    \"\"\"\n",
    "    :param parsed_data: input preprocessed dataset\n",
    "    :return: emissions dataframe and count(y)\n",
    "    ,where emissions dataframe is the count of the sentiments tagged to the tweet whilecount(y) is the number of times the sentiment appears\n",
    "    \"\"\"\n",
    "    data = parsed_data['data']\n",
    "    x_set = parsed_data['x_set']\n",
    "    y_set = parsed_data['y_set']\n",
    "    #create a new datafram of zeros with keys (ie.tweets) as the index and sentiments as the columns\n",
    "    count_emissions_df = pd.DataFrame(np.zeros((len(x_set),len(y_set))),index=x_set,columns=y_set)\n",
    "    count_y = pd.Series(np.zeros(len(y_set)),index=y_set) #create a series object of zeros with index as the sentiments => to store the number times the sentiments appear\n",
    "    #print(count_y)\n",
    "    #print(count_emissions_df) #datafram structure: where its tweets against columns of sentiments\n",
    "    \n",
    "    for word in data:\n",
    "        #print(word) #format of data => [[keys],[values]]\n",
    "        #keys are the tweets, values are the sentiments\n",
    "        tweets_data,sentiments_data = word\n",
    "        \n",
    "        for i in range(len(tweets_data)):\n",
    "            tweet,sentiment = tweets_data[i],sentiments_data[i] #associate the tweet with its sentiment\n",
    "            #print(tweet,sentiment)\n",
    "            #print(sentiment)\n",
    "            #+1 to the row,col, given the tweet, sentiment freq +1\n",
    "            count_emissions_df.loc[tweet,sentiment] += 1 #.loc[] access a grp of rows and columns by labels\n",
    "            #count_emissions_df is for Count(y->x) [counting the number of times a sentiment wrt to the tweet]\n",
    "            count_y[sentiment] += 1 #incrementing the number of time the respective sentiment appear\n",
    "    return count_emissions_df,count_y\n",
    "    \n",
    "def get_emission_params(parsed_data):\n",
    "    \"\"\"\n",
    "    :param parsed_data: input preprocessed dataset\n",
    "    :return: emissions params \n",
    "    \"\"\"\n",
    "    count_emissions_df,count_y = calculate_emission_count(parsed_data)\n",
    "    return count_emissions_df/count_y #e(x|y), where x is the tweet, and y is the sentiment\n",
    "\n",
    "\n",
    "em_df = get_emission_params(obtain_data('sg_train'))\n",
    "#get_emission_counts(obtain_data('sg_train'))\n",
    "em_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b) (10 pts) One problem with estimating the emission parameters is that some words that appear in the test set do not appear in the training set. One simple idea to handle this issue is as follows. First, replace those words that appear less than k times in the training set with a special token #UNK# before training. This leads to a “modiﬁed training set”. We then use such a modiﬁed training set to train our model. During the testing phase, if the word does not appear in the “modiﬁed training set”, we replace that word with #UNK# as well. Set k to 1, implement this ﬁx into your function for computing the emission parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-positive</th>\n",
       "      <th>O</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxonomy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fetus</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Killeen</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#UNK#</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          B-positive         O  B-negative  I-positive  I-neutral  B-neutral  \\\n",
       "cow         0.000154  0.000012         0.0    0.000000    0.00000        0.0   \n",
       "taxonomy    0.000000  0.000008         0.0    0.000000    0.00000        0.0   \n",
       "Fetus       0.000154  0.000000         0.0    0.000000    0.00000        0.0   \n",
       "Killeen     0.000000  0.000000         0.0    0.000235    0.00000        0.0   \n",
       "#UNK#       0.000000  0.000000         0.0    0.000000    0.00006        0.0   \n",
       "\n",
       "          I-negative  \n",
       "cow              0.0  \n",
       "taxonomy         0.0  \n",
       "Fetus            0.0  \n",
       "Killeen          0.0  \n",
       "#UNK#            0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_new_emission_counts(parsed_data,k):\n",
    "    \"\"\"\n",
    "    :param parsed_data: input preprocessed dataset\n",
    "    :param k:  number of occurrences\n",
    "    :return: new dataframe with failed tweets replaced with #UNK# and count(y)\n",
    "    \"\"\"\n",
    "    count_emissions_df,count_y = calculate_emission_count(parsed_data)\n",
    "    #.sum(axis = 1(sum the column), axis = 0 (sum the index))\n",
    "    count_tweet_appearance = count_emissions_df.sum(axis=1)\n",
    "    #print(count_tweet_appearance) #counting the number of times each tweet appears by summing everything across the columns\n",
    "    '''Output of count_tweet appearance eg. \n",
    "        seems                      15.0\n",
    "        https://t.co/h6Ie4IBJ08     1.0\n",
    "        #AnnaVonHausswolff          2.0\n",
    "        Bowery                      2.0\n",
    "        refuge                      2.0\n",
    "        @chuckielufc                1.0\n",
    "        https://t.co/7xSNeWemp1     1.0\n",
    "        @chris_steller              3.0\n",
    "        unexpected                  3.0\n",
    "        #usantdp                    1.0\n",
    "        Ones                        2.0\n",
    "        1979                        4.0\n",
    "        @joceltsh                   1.0\n",
    "        @TomBoxingAsylum            2.0\n",
    "        @thistletat13               2.0\n",
    "        @eibeibb                    2.0\n",
    "        @TalatHussain12             1.0\n",
    "        Ilkeston                    2.0\n",
    "        @ricosua                    1.0\n",
    "        Belarus                     2.0\n",
    "        charms                      2.0\n",
    "        @EvermorSolution            2.0\n",
    "        https://t.co/WrcuWKQ0Xg     2.0\n",
    "        FIRED                       2.0'''\n",
    "    \n",
    "    failed_tweets = count_tweet_appearance[count_tweet_appearance<k]\n",
    "    #print(failed_tweets)\n",
    "    '''eg output if k<3 (ie. tweets with occurence less than 3 times) is:\n",
    "        @Nandos                    1.0\n",
    "        @rcmpgrcpolice             1.0\n",
    "        #yas                       1.0\n",
    "        @just                      2.0\n",
    "        ford                       1.0\n",
    "        attracted                  2.0\n",
    "        @Unitetheunion             1.0\n",
    "        .....        '''\n",
    "    \n",
    "    #replace the tweets that occur less than 1.0 with \"#UNK#\"\n",
    "    #print(failed_tweets.index) #gives all the tweets that <1.0\n",
    "    \n",
    "    replace_tweets = count_emissions_df.loc[failed_tweets.index].sum(axis=0)\n",
    "    replace_tweets.name  = '#UNK#'\n",
    "    \n",
    "    new_df = count_emissions_df.append(replace_tweets)\n",
    "    new_df = new_df.drop(failed_tweets.index,axis=0) #drop all failed_tweets words\n",
    "    headers = new_df.dtypes.index\n",
    "    #print(headers[3]) #gives sentiment O\n",
    "    new_df.at['#UNK#',headers[3]] = 1.0\n",
    "    #print(new_df) #without failed_tweets words inside, has #UNK# row inside at the bottom\n",
    "    \n",
    "    return new_df, count_y\n",
    "\n",
    "def get_new_emission_params(parsed_data,k):\n",
    "    \"\"\"\n",
    "    :param parsed_data: input preprocessed dataset\n",
    "    :param k: number of occurrences\n",
    "    :return: new emission params \n",
    "    \"\"\"\n",
    "    count_emissions_df,count_y = calculate_new_emission_counts(parsed_data,k)\n",
    "    return count_emissions_df/count_y #e(x|y), where x is the tweet, and y is the sentiment\n",
    "\n",
    "#calculate_new_emission_counts(obtain_data('sg_train'),3)\n",
    "new_em_df_parameters = get_new_emission_params(obtain_data('sg_train'),1)\n",
    "#new_em_df_parameters.sum(axis=1) #gives the sum of each rows (individual respective words)\n",
    "'''eg.\n",
    "Throwing          0.000012\n",
    "headquarters      0.000300\n",
    "insist            0.000012\n",
    "except            0.000071\n",
    "Broken            0.000128\n",
    "LCD               0.000124\n",
    "occur             0.000012\n",
    "sound             0.000071\n",
    "'''\n",
    "\n",
    "#new_em_df_parameters.sum(axis=0) #gives the counts of the sentiments\n",
    "new_em_df_parameters.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/dcoE3.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note to self: what is axis=1, axis=0 for dataframe pandas\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://i.stack.imgur.com/dcoE3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2c Implement a simple sentiment analysis system that produces the tag => y∗ = argmax e(x|y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset(file):\n",
    "    \"\"\"\n",
    "    :param file: input preprocessed dataset \n",
    "    :return: new emissions params given preprocessed data and k\n",
    "    \"\"\"\n",
    "    dataset = obtain_data(file)\n",
    "    k = 1\n",
    "    return get_new_emission_params(dataset,k)\n",
    "\n",
    "#single sentiment analysis for a word\n",
    "def sentiment_analysis(emission_param,x):\n",
    "    \"\"\"\n",
    "    :param emission_param: new emissions params dataframe,\n",
    "    :param x: word that you want to predict the sentiment for \n",
    "    :return: predicted sentiment\n",
    "    \"\"\"\n",
    "    #checking if the tweet is an undiscovered/discovered word\n",
    "    #if the word does not appear in training set, then change it to #UNK#\n",
    "    #print(emission_param.index) #gives the individual tweets\n",
    "    if x not in emission_param.index:\n",
    "        x = '#UNK#'\n",
    "    probability = emission_param.loc[x,:]\n",
    "   # print(probability)\n",
    "    max_probability = None\n",
    "    for col in probability.index:\n",
    "        #print(col) #gives the sentiments labels\n",
    "        '''B-positive\n",
    "            ..\n",
    "            ...\n",
    "            -\n",
    "            I-negative\n",
    "            B-neutral\n",
    "            242\n",
    "            O\n",
    "            477\n",
    "            B-negative\n",
    "            .\n",
    "            I-positive\n",
    "            I-neutral'''\n",
    "        if max_probability is None : \n",
    "            max_probability = probability.loc[col]\n",
    "            y = col\n",
    "        elif probability.loc[col]>max_probability: #take the max prob\n",
    "            max_probability = probability.loc[col]\n",
    "            y = col #take the sentiment with the highest probability\n",
    "        \n",
    "    return y\n",
    "        \n",
    "\n",
    "def evaluation(filename,emission_param,outputfile):\n",
    "    \"\"\"\n",
    "    :param filename: input datafile\n",
    "    :param emission_param: emission param dataframe \n",
    "    \"\"\"\n",
    "    with open(filename,'r',encoding=\"utf8\") as inputfile:\n",
    "        lines = inputfile.readlines()\n",
    "        lines = [line.replace('\\n','') for line in lines]\n",
    "        #print(lines)\n",
    "        '''['best', 'friends', 'who', 'cry', 'on', 'FaceTime', 'together', ',', 'stay', 'together', '', \"I'm\", 'at', 'Starbucks',\n",
    "        'in', 'Johor', 'Bahru', ',', 'Johor', 'w', '/', '@cassiecr17', 'https://t.co/3rzoTtjRag', '', 'Reports', 'of', 'a', \n",
    "        'collision', 'on', 'Friary', 'Road', 'in', 'Naas', 'https://t.co/MZgfLNdbyr', '', '♫', 'She', 'Moves', 'In', 'Her', 'Own' ......]\n",
    "        '''\n",
    "        \n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i] #each individual tweets\n",
    "            if line != '': #if line is not empty\n",
    "                line = line + ' ' + sentiment_analysis(emission_param,line)\n",
    "            line += '\\n'\n",
    "            lines[i] = line\n",
    "            \n",
    "        with open(outputfile,\"w\",encoding=\"utf8\") as outputfile:\n",
    "            for line in lines:\n",
    "                outputfile.write(line)\n",
    "    print(\"evaluation completed!\")\n",
    "            \n",
    "        \n",
    "#testcase below:        \n",
    "modified_em_params = get_new_emission_params(obtain_data('sg_train'),1)\n",
    "word = '.'\n",
    "try:\n",
    "    print(modified_em_params.loc[word])\n",
    "except:\n",
    "    word = '#UNK#'\n",
    "    print(modified_em_params.loc[word])\n",
    "sentiment_analysis(modified_em_params,word)\n",
    "emission_param = training_dataset('SG/train')\n",
    "evaluation('SG/dev.in',emission_param,'SG/dev.p2.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for CN dataset:\n",
      "evaluation completed!\n",
      "Analysing for EN dataset:\n",
      "evaluation completed!\n",
      "Analysing for FR dataset:\n",
      "evaluation completed!\n",
      "Analysing for SG dataset:\n",
      "evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "#doing it for all 4 countries\n",
    "for cty in [\"CN\",\"EN\",\"FR\",\"SG\"]:\n",
    "    emission_params = training_dataset(cty+\"/train\") #new emission params are also obtained inside here\n",
    "    print(\"Analysing for \" + cty + \" dataset:\")\n",
    "    evaluation(cty+\"/dev.in\",emission_params,cty+\"/dev.p2.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 238\n",
      "#Entity in prediction: 1128\n",
      "\n",
      "#Correct Entity : 186\n",
      "Entity  precision: 0.1649\n",
      "Entity  recall: 0.7815\n",
      "Entity  F: 0.2723\n",
      "\n",
      "#Correct Entity Type : 78\n",
      "Entity Type  precision: 0.0691\n",
      "Entity Type  recall: 0.3277\n",
      "Entity Type  F: 0.1142\n"
     ]
    }
   ],
   "source": [
    "###evalResult.py\n",
    "\n",
    "import sys\n",
    "import re\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "#Read entities from predcition\n",
    "def get_predicted(predicted, answers=defaultdict(lambda: defaultdict(defaultdict))):\n",
    "\n",
    "    example = 0\n",
    "    word_index = 0\n",
    "    entity = []\n",
    "    last_ne = \"O\"\n",
    "    last_sent = \"\"\n",
    "    last_entity = []\n",
    "\n",
    "    answers[example] = []\n",
    "    for line in predicted:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"##\"):\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            if entity:\n",
    "                answers[example].append(list(entity))\n",
    "                entity = []\n",
    "\n",
    "            example += 1\n",
    "            answers[example] = []\n",
    "            word_index = 0\n",
    "            last_ne = \"O\"\n",
    "            continue\n",
    "        else:\n",
    "            split_line = line.split(separator)\n",
    "            #word = split_line[0]\n",
    "            value = split_line[outputColumnIndex]\n",
    "            ne = value[0]\n",
    "            sent = value[2:]\n",
    "\n",
    "\n",
    "            last_entity = []\n",
    "\n",
    "            #check if it is start of entity\n",
    "            if ne == 'B' or (ne == 'I' and last_ne == 'O') or (last_ne != 'O' and ne == 'I' and last_sent != sent):\n",
    "                if entity:\n",
    "                    last_entity = list(entity)\n",
    "\n",
    "                entity = [sent]\n",
    "                    \n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'I':\n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'O':\n",
    "                if last_ne == 'B' or last_ne == 'I':\n",
    "                    last_entity =list(entity)\n",
    "                entity = []\n",
    "\n",
    "\n",
    "            if last_entity:\n",
    "                answers[example].append(list(last_entity))\n",
    "                last_entity = []\n",
    "\n",
    "        last_sent = sent\n",
    "        last_ne = ne\n",
    "        word_index += 1\n",
    "\n",
    "    if entity:\n",
    "        answers[example].append(list(entity))\n",
    "\n",
    "\n",
    "    return answers\n",
    "\n",
    "\n",
    "\n",
    "#Read entities from gold data\n",
    "def get_observed(observed):\n",
    "\n",
    "\n",
    "    example = 0\n",
    "    word_index = 0\n",
    "    entity = []\n",
    "    last_ne = \"O\"\n",
    "    last_sent = \"\"\n",
    "    last_entity = []\n",
    "\n",
    "    observations=defaultdict(defaultdict)\n",
    "    observations[example] = []\n",
    "\n",
    "    for line in observed:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"##\"):\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            if entity:\n",
    "                observations[example].append(list(entity))\n",
    "                entity = []\n",
    "\n",
    "            example += 1\n",
    "            observations[example] = []\n",
    "            word_index = 0\n",
    "            last_ne = \"O\"\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            split_line = line.split(separator)\n",
    "            word = split_line[0]\n",
    "            value = split_line[outputColumnIndex]\n",
    "            ne = value[0]\n",
    "            sent = value[2:]\n",
    "\n",
    "\n",
    "            last_entity = []\n",
    "\n",
    "            #check if it is start of entity, suppose there is no weird case in gold data\n",
    "            if ne == 'B' or (ne == 'I' and last_ne == 'O') or (last_ne != 'O' and ne == 'I' and last_sent != sent):\n",
    "                if entity:\n",
    "                    last_entity = entity\n",
    "\n",
    "                entity = [sent]\n",
    "                    \n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'I':\n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'O':\n",
    "                if last_ne == 'B' or last_ne == 'I':\n",
    "                    last_entity = entity\n",
    "                entity = []\n",
    "\n",
    "\n",
    "            if last_entity:\n",
    "                observations[example].append(list(last_entity))\n",
    "                last_entity = []\n",
    "\n",
    "\n",
    "        last_ne = ne\n",
    "        last_sent = sent\n",
    "        word_index += 1\n",
    "\n",
    "    if entity:\n",
    "        observations[example].append(list(entity))\n",
    "\n",
    "    return observations\n",
    "\n",
    "#Print Results and deal with division by 0\n",
    "def printResult(evalTarget, num_correct, prec, rec):\n",
    "    if abs(prec + rec ) < 1e-6:\n",
    "        f = 0\n",
    "    else:\n",
    "        f = 2 * prec * rec / (prec + rec)\n",
    "    print('#Correct', evalTarget, ':', num_correct)\n",
    "    print(evalTarget, ' precision: %.4f' % (prec))\n",
    "    print(evalTarget, ' recall: %.4f' %   (rec))\n",
    "    print(evalTarget, ' F: %.4f' % (f))\n",
    "\n",
    "#Compare results bewteen gold data and prediction data\n",
    "def compare_observed_to_predicted(observed, predicted):\n",
    "\n",
    "    correct_sentiment = 0\n",
    "    correct_entity = 0\n",
    "\n",
    "    total_observed = 0.0\n",
    "    total_predicted = 0.0\n",
    "\n",
    "    #For each Instance Index example (example = 0,1,2,3.....)\n",
    "    for example in observed:\n",
    "\n",
    "        if example in discardInstance:\n",
    "            continue\n",
    "\n",
    "        observed_instance = observed[example]\n",
    "        predicted_instance = predicted[example]\n",
    "\n",
    "        #Count number of entities in gold data\n",
    "        total_observed += len(observed_instance)\n",
    "        #Count number of entities in prediction data\n",
    "        total_predicted += len(predicted_instance)\n",
    "\n",
    "        #For each entity in prediction\n",
    "        for span in predicted_instance:\n",
    "            span_begin = span[1]\n",
    "            span_length = len(span) - 1\n",
    "            span_ne = (span_begin, span_length)\n",
    "            span_sent = span[0]\n",
    "\n",
    "            #For each entity in gold data\n",
    "            for observed_span in observed_instance:\n",
    "                begin = observed_span[1]\n",
    "                length = len(observed_span) - 1\n",
    "                ne = (begin, length)\n",
    "                sent = observed_span[0]\n",
    "\n",
    "                #Entity matched\n",
    "                if span_ne == ne:\n",
    "                    correct_entity += 1\n",
    "\n",
    "\n",
    "                    #Entity & Sentiment both are matched\n",
    "                    if span_sent == sent:\n",
    "                        correct_sentiment += 1\n",
    "\n",
    "    print()\n",
    "    print('#Entity in gold data: %d' % (total_observed))\n",
    "    print('#Entity in prediction: %d' % (total_predicted))\n",
    "    print()\n",
    "\n",
    "    prec = correct_entity/total_predicted\n",
    "    rec = correct_entity/total_observed\n",
    "    printResult('Entity', correct_entity, prec, rec)\n",
    "    print()\n",
    "\n",
    "    prec = correct_sentiment/total_predicted\n",
    "    rec = correct_sentiment/total_observed\n",
    "    printResult('Entity Type',correct_sentiment, prec, rec)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############Main Function##################\n",
    "\n",
    "if len(sys.argv) < 3:\n",
    "    print ('Please make sure you have installed Python 3.4 or above!')\n",
    "    print (\"Usage on Windows:  python evalResult.py [gold file] [prediction file]\")\n",
    "    print (\"Usage on Linux/Mac:  python3 evalResult.py [gold file] [prediction file]\")\n",
    "    sys.exit()\n",
    "\n",
    "gold = open('FR\\dev.out', \"r\", encoding='UTF-8')\n",
    "prediction = open('FR\\dev.p2.out', \"r\", encoding='UTF-8')\n",
    "discardInstance = []\n",
    "\n",
    "\n",
    "if len(sys.argv) > 3 and sys.argv[3] == 'filter':\n",
    "    filterInst_file = open(sys.argv[1] + '.filter', \"r\", encoding='UTF-8')\n",
    "    for line in filterInst_file:\n",
    "        line = line.strip('\\n')\n",
    "        line = line.strip('\\r')\n",
    "        instID = int(line)\n",
    "        discardInstance.append(instID)\n",
    "\n",
    "\n",
    "#column separator\n",
    "separator = ' '\n",
    "\n",
    "#the column index for tags\n",
    "outputColumnIndex = 1\n",
    "#Read Gold data\n",
    "observed = get_observed(gold)\n",
    "\n",
    "#Read Predction data\n",
    "predicted = get_predicted(prediction)\n",
    "\n",
    "#Compare\n",
    "compare_observed_to_predicted(observed, predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >python3 evalResult.py EN/dev.out EN/dev.p2.out\n",
    "Entity in gold data: 802\n",
    "Entity in prediction: 926\n",
    "\n",
    "Correct Entity : 576\n",
    "Entity  precision: 0.6220\n",
    "Entity  recall: 0.7182\n",
    "Entity  F: 0.6667\n",
    "\n",
    "Correct Entity Type : 507\n",
    "Entity Type  precision: 0.5475\n",
    "Entity Type  recall: 0.6322\n",
    "Entity Type  F: 0.5868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >python3 evalResult.py CN/dev.out CN/dev.p2.out\n",
    "Entity in gold data: 1081\n",
    "Entity in prediction: 4939\n",
    "\n",
    "Correct Entity : 613\n",
    "Entity  precision: 0.1241\n",
    "Entity  recall: 0.5671\n",
    "Entity  F: 0.2037\n",
    "\n",
    "Correct Entity Type : 436\n",
    "Entity Type  precision: 0.0883\n",
    "Entity Type  recall: 0.4033\n",
    "Entity Type  F: 0.1449"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >python3 evalResult.py FR/dev.out FR/dev.p2.out\n",
    "Entity in gold data: 238\n",
    "Entity in prediction: 1128\n",
    "\n",
    "Correct Entity : 186\n",
    "Entity  precision: 0.1649\n",
    "Entity  recall: 0.7815\n",
    "Entity  F: 0.2723\n",
    "\n",
    "Correct Entity Type : 78\n",
    "Entity Type  precision: 0.0691\n",
    "Entity Type  recall: 0.3277\n",
    "Entity Type  F: 0.1142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >python3 evalResult.py SG/dev.out SG/dev.p2.out\n",
    "Entity in gold data: 4092\n",
    "Entity in prediction: 11598\n",
    "\n",
    "Correct Entity : 2291\n",
    "Entity  precision: 0.1975\n",
    "Entity  recall: 0.5599\n",
    "Entity  F: 0.2920\n",
    "\n",
    "Correct Entity Type : 1315\n",
    "Entity Type  precision: 0.1134\n",
    "Entity Type  recall: 0.3214\n",
    "Entity Type  F: 0.1676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
